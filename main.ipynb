{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI in Medicine I - Practical 1: Brain Age Estimation\n",
    "\n",
    "Predicting the age of a patient from their brain MRI scan can have diagnostic value for a number of diseases that may cause structural changes and potential damage to the brain. A discrepancy between the predicted age and the real, chronological age of a patient might indicate the presence of disease. This requires an accurate predictor of brain age which may be learned from a set of healthy reference subjects, given their brain MRI data and their actual age.\n",
    "\n",
    "The objective for the coursework is to implement two supervised learning approaches for age regression from brain MRI. We provide data from a total of 652 healthy subjects, that is split into different development sets and a hold-out test set on which you will evaluate your final prediction accuracy.\n",
    "Each approach will require a processing pipeline with different components that you will need to implement using methods that were discussed in the lectures and tutorials. There are two dedicated parts in the Jupyter notebook for each approach which contain some detailed instructions and some helper code.\n",
    "\n",
    "**Make sure to select the correct runtime when working in Google Colab (GPU)**\n",
    "\n",
    "### Read the text descriptions and code cells carefully and look out for the cells marked with 'TASK' and 'ADD YOUR CODE HERE'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell when in Google Colab\n",
    "! git init\n",
    "! git remote add origin https://github.com/compai-lab/aim-practical-1-brain-age-estimation.git\n",
    "! git fetch\n",
    "! git checkout -t origin/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://www.dropbox.com/s/w9njau9t6rrheel/brainage-data.zip\n",
    "! unzip brainage-data.zip\n",
    "! wget https://www.dropbox.com/s/f5mt8p9pkszff3x/brainage-testdata.zip\n",
    "! unzip brainage-testdata.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from data_utils import get_image_dataloaders, load_nii, load_segmentations\n",
    "from plot_utils import plot_segmentations\n",
    "from models import BrainAgeCNN\n",
    "from utils import AvgMeter, mean_absolute_error, seed_everything, TensorboardLogger\n",
    "%load_ext tensorboard\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started and familiarise ourselves with the data\n",
    "\n",
    "We provide the data of 652 subjects from which we use 500 for training, 47 for validation, and the rest for testing your final model.\n",
    "The following cells provide helper functions to load the data and provide an overview and visualization of the statistics over the total population of the 652 subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the meta data using pandas\n",
    "meta_data_all = pd.read_csv('./data/brain_age/meta/meta_data_all.csv')\n",
    "meta_data_all.head()  # show the first five data entries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at some population statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"gender_text\", data=meta_data_all, kind=\"count\")\n",
    "plt.title('Gender distribution')\n",
    "plt.xlabel('Gender')\n",
    "plt.show()\n",
    "sns.distplot(meta_data_all['age'], bins=[10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "plt.title('Age distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.show()\n",
    "plt.scatter(range(len(meta_data_all['age'])), meta_data_all['age'], marker='.')\n",
    "plt.grid()\n",
    "plt.xlabel('Subject')\n",
    "plt.ylabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imaging data\n",
    "Let's check out the imaging data that is available for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './data/brain_age/images/sub-CC110033_T1w_unbiased.nii.gz'\n",
    "\n",
    "image = nib.load(file).get_fdata()\n",
    "\n",
    "f, axarr = plt.subplots(1, 3)\n",
    "H, W, D = image.shape\n",
    "axarr[0].imshow(np.flip(image[H // 2, :, :].T, axis=0), cmap='gray')\n",
    "axarr[1].imshow(np.flip(image[:, W // 2, :].T, axis=0), cmap='gray')\n",
    "axarr[2].imshow(image[:, :, D // 2].T, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Age prediction segmentation features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach aims to regress the age of a subject from the volumes of brain tissues, including grey matter (GM), white matter (WM), and cerebrospinal fluid (CSF). It is known that with increasing age the ventricles enlarge (filled with CSF), while it is assumed that grey and white matter volume might decrease.\n",
    "\n",
    "Different regression techniques should be explored, and it might be beneficial to investigate what the best set of features is for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and visualization\n",
    "\n",
    "Let's first load all provided tissue segmentations and plot one of them.JJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob('data/brain_age/segs_refs/*'))\n",
    "filenames, segmentations = load_segmentations(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = load_nii(f'data/brain_age/images/sub-{filenames[1]}_T1w_unbiased.nii.gz')\n",
    "plot_segmentations(im, segmentations[1], i=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature identification: TASK\n",
    "\n",
    "Implement a function that calculates volume features given the three tissue volumes and the overal\n",
    "brain volume (which can be calculated from the brain masks). You should use this function to\n",
    "construct a big matrix X with a row for each subject and features across the columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv('data/brain_age/meta/meta_data_all.csv')\n",
    "labels = list(df_labels[df_labels['subject_id'].isin(filenames)].age)\n",
    "assert list(df_labels[df_labels['subject_id'].isin(filenames)]['subject_id']) == filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(labels)\n",
    "\n",
    "# --------------------------- ADD YOUR CODE HERE ------------------------------\n",
    "X = None\n",
    "# ----------------------------------- END -------------------------------------\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation: TASK\n",
    "\n",
    "Here, you should experiment with different regression methods and evaluate them using cross-validation. At least two different regression methods should be used. (Hint: sklearn has implementations of cross_validation and different regression models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, X, y, folds):\n",
    "    # --------------------------- ADD YOUR CODE HERE ------------------------------\n",
    "    score = None\n",
    "    # ----------------------------------- END -------------------------------------\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to import models from scipy here\n",
    "# --------------------------- ADD YOUR CODE HERE ------------------------------\n",
    "\n",
    "# ----------------------------------- END -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Age prediction from images using CNNs\n",
    "Here we will use a convolutional neural network to directly predict a subject's age.\n",
    "You will need to implement a CNN model in PyTorch that takes an MRI scan as an input and maps it to a one-dimensional, real-valued output.\n",
    "\n",
    "*Note:* You may want to set up a pre-processing pipeline that involves intensity normalisation\n",
    "\n",
    "Familiarize yourself with the training and test-functions below. Note, how the model classes we use have a .train_step() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, model, optimizer, train_loader, val_loader, writer):\n",
    "    model.train()\n",
    "    step = 0\n",
    "    pbar = tqdm(total=config.val_freq,\n",
    "                desc=f'Training')\n",
    "    avg_loss = AvgMeter()\n",
    "\n",
    "    while True:\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(config.device)\n",
    "            y = y.to(config.device)\n",
    "            pbar.update(1)\n",
    "\n",
    "            # Training step\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.train_step(x, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss.add(loss.detach().item())\n",
    "\n",
    "            # Increment step\n",
    "            step += 1\n",
    "\n",
    "            if step % config.log_freq == 0 and not step % config.val_freq == 0:\n",
    "                train_loss = avg_loss.compute()\n",
    "                writer.log({'train/loss': train_loss}, step=step)\n",
    "\n",
    "            # Validate and log at validation frequency\n",
    "            if step % config.val_freq == 0:\n",
    "                # Reset avg_loss\n",
    "                train_loss = avg_loss.compute()\n",
    "                avg_loss = AvgMeter()\n",
    "\n",
    "                # Get validation results\n",
    "                val_results = validate(\n",
    "                    model,\n",
    "                    val_loader,\n",
    "                    config,\n",
    "                )\n",
    "\n",
    "                # Print current performance\n",
    "                print(f\"Finished step {step} of {config.num_steps}. \"\n",
    "                      f\"Train loss: {train_loss} - \"\n",
    "                      f\"val loss: {val_results['val/loss']:.4f} - \"\n",
    "                      f\"val MAE: {val_results['val/MAE']:.4f}\")\n",
    "\n",
    "                # Write to tensorboard\n",
    "                writer.log(val_results, step=step)\n",
    "\n",
    "                # Reset progress bar\n",
    "                pbar = tqdm(total=config.val_freq, desc='Training')\n",
    "\n",
    "            if step >= config.num_steps:\n",
    "                print(f'\\nFinished training after {step} steps\\n')\n",
    "                return model, step\n",
    "\n",
    "\n",
    "def validate(model, val_loader, config, show_plot=False):\n",
    "    model.eval()\n",
    "    avg_val_loss = AvgMeter()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for x, y in val_loader:\n",
    "        x = x.to(config.device)\n",
    "        y = y.to(config.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss, pred = model.train_step(x, y, return_prediction=True)\n",
    "        avg_val_loss.add(loss.item())\n",
    "        preds.append(pred.cpu())\n",
    "        targets.append(y.cpu())\n",
    "\n",
    "    preds = torch.cat(preds)\n",
    "    targets = torch.cat(targets)\n",
    "    mae = mean_absolute_error(preds, targets)\n",
    "    f = plot_results(preds, targets, show_plot)\n",
    "    model.train()\n",
    "    return {\n",
    "        'val/loss': avg_val_loss.compute(),\n",
    "        'val/MAE': mae,\n",
    "        'val/MAE_plot': f\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_results(preds: Tensor, targets: Tensor, show_plot: bool = False):\n",
    "    # Compute the mean absolute error\n",
    "    mae_test = mean_absolute_error(preds, targets)\n",
    "    # Sort preds and targets to ascending targets\n",
    "    sort_inds = targets.argsort()\n",
    "    targets = targets[sort_inds].numpy()\n",
    "    preds = preds[sort_inds].numpy()\n",
    "\n",
    "    f = plt.figure()\n",
    "    plt.plot(targets, targets, 'r.')\n",
    "    plt.plot(targets, preds, '.')\n",
    "    plt.plot(targets, targets + mae_test, 'gray')\n",
    "    plt.plot(targets, targets - mae_test, 'gray')\n",
    "    plt.suptitle('Mean Average Error')\n",
    "    plt.xlabel('True Age')\n",
    "    plt.ylabel('Age predicted')\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a config for our script. The given config only includes the bare minimum. You can and will extend it later to include own options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to play around with the parameters here\n",
    "# --------------------------- ADD YOUR CODE HERE ------------------------------\n",
    "config = Namespace()\n",
    "config.img_size = 96\n",
    "config.batch_size = None\n",
    "config.num_workers = 0\n",
    "\n",
    "config.log_dir = './logs'\n",
    "config.val_freq = 50\n",
    "config.log_freq = 10\n",
    "\n",
    "config.seed = 0\n",
    "config.device = 'cuda'\n",
    "\n",
    "seed_everything(config.seed)\n",
    "# ----------------------------------- END -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloading - TASK:\n",
    "\n",
    "Finish the functions to generate the image dataloaders in ```data_utils.py```.\n",
    "All tasks are indicated by 'ADD YOUR CODE HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataloaders = get_image_dataloaders(\n",
    "    img_size=config.img_size,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - TASK:\n",
    "\n",
    "Create your model in ```models.py```. The basic logic is already given.\n",
    "\n",
    "You need to complete the ```__init__``` function, the ```forward``` pass, and the loss-function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "model = BrainAgeCNN().to(config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config and Train: TASK\n",
    "\n",
    "Finish the config and train your model. \n",
    "\n",
    "**Play around with different model architectures and hyperparameters until you find a model that reaches a satisfactory Mean Average Error of around 8.0**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to add more hyperparameters here\n",
    "# --------------------------- ADD YOUR CODE HERE ------------------------------\n",
    "config.lr = None\n",
    "config.betas = None\n",
    "config.num_steps = None\n",
    "# ----------------------------------- END -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init optimizers\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config.lr,\n",
    "    betas=config.betas\n",
    ")\n",
    "# Init tensorboard\n",
    "writer = TensorboardLogger(config.log_dir, config)\n",
    "# Train\n",
    "model, step = train(\n",
    "    config=config,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=dataloaders['train'],\n",
    "    val_loader=dataloaders['val'],\n",
    "    writer=writer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard logging\n",
    "\n",
    "Open Tensorboard to see your training performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final testing\n",
    "\n",
    "Evaluate the final performance of your model. **This should only be done once with your final model!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_results = validate(model, dataloaders['test'], config, show_plot=True)\n",
    "test_results = {k.replace('val', 'test'): v for k, v in test_results.items()}\n",
    "writer.log(test_results, step)\n",
    "print(f'Test loss: {test_results[\"test/loss\"]:.4f}')\n",
    "print(f'Test MAE: {test_results[\"test/MAE\"]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "The goal of this bonus exercise is to track the carbon footprint of the brain age regression model you\n",
    "implemented. You may use any tool you’d like. This exercise is purposely open, there is no material provided so you should experiment with the libraries that exist and the training procedure of your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- ADD YOUR CODE HERE ------------------------------\n",
    "\n",
    "# ----------------------------------- END -------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "59efc9589e5e0a10197249f838db0eb26aa8a323367b3d188d3e2ee96ab5bb66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
